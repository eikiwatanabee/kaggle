{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\n# Load the data\ntrain = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ngreeks = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')\n\n\n# Merge train and greeks based on 'Id'\nmerged_train = pd.merge(train, greeks, on='Id', how='left')\nsummary_stats = merged_train.describe()\n\nprint(summary_stats)\n\n# # Print the number of missing values in each column\n# print(merged_train.isnull().sum())\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T04:39:22.066482Z","iopub.execute_input":"2023-06-13T04:39:22.066913Z","iopub.status.idle":"2023-06-13T04:39:22.186967Z","shell.execute_reply.started":"2023-06-13T04:39:22.066883Z","shell.execute_reply":"2023-06-13T04:39:22.186293Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"               AB            AF           AH          AM          AR  \\\ncount  617.000000    617.000000   617.000000  617.000000  617.000000   \nmean     0.477149   3502.013221   118.624513   38.968552   10.128242   \nstd      0.468388   2300.322717   127.838950   69.728226   10.518877   \nmin      0.081187    192.593280    85.200147    3.177522    8.138688   \n25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \nmax      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n\n               AX          AY          AZ           BC           BD   ...  \\\ncount  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \nmean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \nstd      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \nmin      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \nmax     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n\n               FL           FR          FS          GB           GE  \\\ncount  616.000000   617.000000  615.000000  617.000000   617.000000   \nmean     5.433199     3.533905    0.421501   20.724856   131.714987   \nstd     11.496257    50.181948    1.305365    9.991907   144.181524   \nmin      0.173229     0.497060    0.067730    4.102182    72.611063   \n25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n50%      3.028141     1.131000    0.250601   18.771436    72.611063   \n75%      6.238814     1.512060    0.535067   25.608406   127.591671   \nmax    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n\n                  GF          GH          GI          GL       Class  \ncount     617.000000  617.000000  617.000000  616.000000  617.000000  \nmean    14679.595398   31.489716   50.584437    8.530961    0.175041  \nstd     19352.959387    9.864239   36.266251   10.327010    0.380310  \nmin        13.038894    9.432735    0.897628    0.001129    0.000000  \n25%      2798.992584   25.034888   23.011684    0.124392    0.000000  \n50%      7838.273610   30.608946   41.007968    0.337827    0.000000  \n75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \nmax    143790.071200   81.210825  191.194764   21.978000    1.000000  \n\n[8 rows x 56 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# If there are missing values, fill them with a suitable method. Here we fill with the most frequent value in each column.\nimputer = SimpleImputer(strategy='most_frequent')\nmerged_train_imputed = pd.DataFrame(imputer.fit_transform(merged_train), columns=merged_train.columns)\n\n# One-hot encode the categorical features\ncategorical_cols = ['Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon']  # Please specify the categorical columns\n\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\ntrain_encoded = pd.DataFrame(encoder.fit_transform(merged_train_imputed[categorical_cols]))\n\n# Rename the encoded columns\ntrain_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n\n# Replace the original columns with the new one-hot encoded columns\nmerged_train_imputed = merged_train_imputed.drop(categorical_cols, axis=1)\nmerged_train_encoded = pd.concat([merged_train_imputed, train_encoded], axis=1)\n\n# Separate the target variable and explanatory variables\nX = merged_train_encoded.drop(['Id', 'Class'], axis=1)\ny = merged_train_encoded['Class']","metadata":{"execution":{"iopub.status.busy":"2023-06-13T04:31:51.088757Z","iopub.execute_input":"2023-06-13T04:31:51.089108Z","iopub.status.idle":"2023-06-13T04:31:51.123397Z","shell.execute_reply.started":"2023-06-13T04:31:51.089080Z","shell.execute_reply":"2023-06-13T04:31:51.122196Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(617, 58)\n","output_type":"stream"}]}]}